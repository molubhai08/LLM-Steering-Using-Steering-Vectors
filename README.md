# LLM-Steering-Using-Steering-Vectors

This project explores **identity steering in large language models (LLMs)** using **activation steering vectors**.
The goal is to **systematically discover where, how, and how strongly** a modelâ€™s internal representations can be modified to induce a **stable identity shift** (e.g., from *AI assistant* â†’ *Golden Retriever* ğŸ•).

---

## ğŸ“Œ Key Contributions

âœ” Layer-wise steering vector extraction
âœ” Coefficient sweep to find effective steering strength
âœ” Single-layer vs multi-layer steering comparison
âœ” MLP hook vs residual hook analysis
âœ” Discovery of **late-layer dominance** in identity control
âœ” Final optimized function for stable identity steering

---

## ğŸ§  Core Concept

A **steering vector** is computed as the difference between hidden activations of two contrasting concepts:

```
steering_vector = mean(hidden_target âˆ’ hidden_base)
```

These vectors are injected into transformer layers during generation using **forward hooks**, modifying the modelâ€™s internal computation **without fine-tuning**.

---

## ğŸ§ª Experiment Phases

### **Phase 1 â€” Coefficient Sweep per Layer**

**Objective:**
Find how much steering strength (`coeff`) each layer can tolerate before becoming unstable.

**Method:**

* Extract AI â†” Dog identity vectors
* Inject steering at one layer at a time
* Sweep coefficients from `5 â†’ 30`
* Score outputs for â€œdog-likeâ€ behavior

**Finding:**

* Mid layers respond weakly
* Late layers respond strongly but require higher coefficients

---

### **Phase 2 â€” Multi-Layer Steering**

**Hypothesis:**
Single-layer steering is overwritten by later layers.

**Method:**

* Apply steering to **multiple layers simultaneously**
* Test different layer combinations:

  * Middle layers
  * Late layers
  * Early + Late
  * Wide ranges

**Finding:**

* Multi-layer steering preserves identity better
* Later layers dominate final behavior

---

### **Phase 3 â€” Pure Concept Extraction**

Instead of instruction prompts, **pure descriptive text** is used to extract cleaner concept vectors.

âœ” Reduces instruction leakage
âœ” Produces more stable identity vectors

---

### **Phase 4 â€” Late-Layer Optimization**

**Breakthrough Result**

Best configuration found:

```
Layers: [20, 22, 24, 26]
Coefficient: 30â€“35
Hook type: MLP (pre-residual)
```

This yields:

* Coherent
* Persistent
* Semantically consistent dog identity

---

### **Phase 5 â€” Residual vs MLP Hook Comparison**

| Hook Type     | Effect                              |
| ------------- | ----------------------------------- |
| MLP Hook      | Stronger identity control           |
| Residual Hook | More global but less precise        |
| Late MLP      | Best balance of coherence & control |

---

## âš™ï¸ Model & Environment

* **Model:** `microsoft/Phi-3-mini-4k-instruct`
* **Framework:** PyTorch + Hugging Face Transformers
* **Hardware:** CUDA GPU required
* **Cache:** Disabled (`use_cache=False`) for correct hooks

---

## ğŸ“‚ File Structure

```
steering_vectors.py
â”œâ”€ Layer-wise coefficient sweep
â”œâ”€ Multi-layer steering experiments
â”œâ”€ Pure concept vector extraction
â”œâ”€ Late-layer optimization
â”œâ”€ MLP hook steering
â”œâ”€ Residual hook steering
â””â”€ Interactive demo & comparison
```

---

## ğŸ§ª Example Usage

```python
response = generate_as_dog(
    prompt="Who are you?",
    layers=[20, 22, 24, 26],
    coeff=32.0,
    temperature=0.8
)
print(response)
```

---

## ğŸ”¬ Key Findings

* Identity is **not localized** to a single layer
* Later layers have **higher semantic leverage**
* Steering strength must scale with layer depth
* Multi-layer steering prevents identity correction
* MLP hooks outperform residual hooks for concept control

---

## âš ï¸ Limitations

* Model-specific (Phi-3 behavior may not generalize)
* Over-steering causes repetition or incoherence
* High compute cost (cache disabled)
* Ethical risks if used for manipulation
* Identity control â‰  factual control

---


